{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "flexible-madness",
   "metadata": {},
   "source": [
    "# Градиентный спуск (15 баллов)\n",
    "\n",
    "В этой домашней работе мы попробуем разобраться в том, что же такое градиентный спуск, как он работает и что можно делать с его помощью. Обычно для этих целей используются пара готовых классов из `sklearn`: `SGDClassifier` и `SGDRegressor`, на основании которых написано еще много чего интересного. Можно было бы воспользоваться этими классами и, подражая обезьяне, пробовать крутить различные ручки-параметры, пытаясь понять, что же они значат и как работают. Но это не наш путь, поэтому мы напишем все сами.\n",
    "\n",
    "## Что будем делать\n",
    "\n",
    "Градиентный спуск это основной метод оптимизации в машинном обучении, и он нам еще не раз пригодится. Чтобы не терять свои наработки в дюжине тетрадок, мы напишем свою упрощенную версию библиотеки `sklearn`, добавляя туда функционал от домашки к домашке. Скелет нашего фреймворка в самом начале будет крутиться вокруг трех классов:\n",
    "\n",
    "`_losses.py` -- функции потерь для различных линейных моделей. Каждая функция потерь имеет два метода: `loss`, который непосредственно вычисляет значение функции потерь, и `dloss`, который вычисляет значение ее производной (градиента). В качестве аргументов эти функции принимают предсказанное значение `p` и истинное значение `y` для объекта.\n",
    "\n",
    "`_sgd.py` -- основа основ, тут находится метод `sgd`, который для полученной лосс функции проходит `epochs` итераций градиентного спуска, обновляя полученные веса и смещения на основании входных данных. Основную часть работы мы будем вести здесь.\n",
    "\n",
    "`SGDRegressor.py` -- обертка над `sgd`, обрабатывает входные данные и реализует интерфейсы, принятые в `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-double",
   "metadata": {},
   "source": [
    "# SquaredLoss (0.5 балла)\n",
    "\n",
    "Чтобы в домашку было проще вкатится, мы начнем с малого, а именно -- реализуем квадратичную функцию потерь. Как мы помним из теории, квадратичная функция потерь на вход принимает два числа (`p` и `y` в нашем случае), а зачем вычисляется по следующей формулe:\n",
    "\n",
    "$SE = (y - \\hat{y})^2$, где $\\hat{y}$ это наше предсказание, или $p$.\n",
    "\n",
    "Для каждого $i$-го объекта лосс вычисляется по следующей формуле:\n",
    "\n",
    "$L\\left(y_i, f(x_i)\\right) = \\frac{1}{2}\\left(y_i - f(x_i)\\right)^2$ или $L(y_i, p_i) = \\frac{1}{2}\\left(y_i - p_i\\right)^2$\n",
    "\n",
    "Для начала реализуйте эту формулу и ее производную в заранее подготовленном классе `SquaredLoss`, который можно найти в `_losses.py`. Места где от вас хотят что-то увидеть помечены строчкой `<YOUR CODE HERE>`. Сам класс выглядит примерно вот так:\n",
    "\n",
    "Ячейку ниже править не надо, она только для примера, пишите код в `_losses.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquaredLoss(RegressionLoss):\n",
    "    def loss(self, p: float, y: float) -> float:\n",
    "        # <YOUR CODE HERE>\n",
    "\n",
    "    def dloss(self, p: float, y: float) -> float:\n",
    "        # <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-means",
   "metadata": {},
   "source": [
    "После этого, чтобы удостоверится в правильности реализации формул, прогоните тесты для проверки. Это можно сделать как в ячейке ниже, так и в консоли, запустив следующую команду:\n",
    "\n",
    "`pytest test_sgd.py -k TestSquaredLoss -v`\n",
    "\n",
    "Для запуска в ячейке перед командой введите восклицательный знак (просто запустите ячейку ниже, он там уже есть). Для проверки конечно было бы удобно, если бы все такие ячейки были выполнены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "forbidden-original",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 71 deselected / 2 selected                                \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestSquaredLoss::test_loss \u001b[32mPASSED\u001b[0m\u001b[32m                           [ 50%]\u001b[0m\n",
      "test_sgd.py::TestSquaredLoss::test_dloss \u001b[32mPASSED\u001b[0m\u001b[32m                          [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m71 deselected\u001b[0m\u001b[32m in 0.57s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestSquaredLoss -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-tradition",
   "metadata": {},
   "source": [
    "Как понять, что все прошло успешно? Есть несколько признаков\n",
    "\n",
    "* `test_gd.py ..` -- справа от имени файла с тестом только точки, никаких букв `F`;\n",
    "* `[100%]` -- еще правее цифра 100%;   \n",
    "* В полосе снизу написано `2 passed`, нет слова `failed` и она зеленого цвета, а не красного. \n",
    "\n",
    "Если что-то пошло не так, проверьте свой код и посмотрите в тесты еще раз. Повторяйте до сходимости, после чего переходите к следующему пункту."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-adventure",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SGD (2 балла)\n",
    "\n",
    "Теперь мы перейдем к основной части нашей работы -- алгоритму стохастического градиентного спуска. Заготовка функции, в которой мы его реализуем лежит в `sgd.py`. Не пугайтесь, хоть там и много аргументов, все они описаны в докблок комментарии в начале функции. Нас сейчас будут интересовать далеко не все, а только самые необходимые для работы:\n",
    "\n",
    "* `weights` -- вектор весов линейной модели (если кто помнит, их количество равно количеству признаков);\n",
    "* `intercept` -- bias, смещение плоскости относительно нуля;\n",
    "* `loss` -- класс, реализующий интерфейс функции потерь, такую мы уже реализовали выше;\n",
    "* `X` -- список объектов из тренировочной выборки;\n",
    "* `y` -- список таргетов для этих объектов;\n",
    "* `max_iter` -- максимальное количество итераций (или шагов, или *эпох*) градиентного спуска;\n",
    "* `fit_intercept` -- обучать ли смещение (intercept) или нет\n",
    "* `eta0` -- под этим странным именем скрывается скорость обучения, или *learning rate*.\n",
    "\n",
    "Для решения этой задачи напомню алгоритм стохастического градиентного спуска в рамках регрессии, которую мы решаем:\n",
    "\n",
    "## Математическая формулировка\n",
    "\n",
    "Дано множество объектов $(x_1, y_1), ..., (x_n, y_n)$, где $x_i\\in\\mathbb{R}^m$ и $y_i\\in\\mathbb{R}$. Наша цель -- обучить линейную модель $f(x) = w^Tx + b$ с весами $w\\in\\mathbb{R}^m$ и смещением $b\\in\\mathbb{R}$. Для того, чтобы найти эти параметры, мы минимизируем регуляризованную ошибку на тренировочной выборке:\n",
    "\n",
    "$E(w, b) = \\frac{1}{n}\\sum_{i=1}^{n}L(y_i, f(x_i)) + \\alpha R(w)$,\n",
    "\n",
    "где $L$ это функция потерь, а $R$ это регуляризатор. $\\alpha > 0$ это неотрицательный параметр, который контролирует силу регуляризации. В этой домашней работе мы будем считать, что $\\alpha = 0$ и регуляризация не используется.\n",
    "\n",
    "В качестве алгоритма минимизации используется стохастический градиентный спуск (stochastic gradient descent, SGD). SGD аппроксимирует истинное значение ошибки $E(w, b)$ рассматривая по одному объекту из тренировочный выборки за раз. Алгоритм перебирает все объекты тренировочный выборки и для каждого обновляет параметры модели в соответствии с правилами, описанными следующими формулами:\n",
    "\n",
    "$w\\leftarrow w -\\eta\\left[\\frac{\\partial{L(w^Tx_i + b, y_i)}}{\\partial{w}}\\right]$\n",
    "\n",
    "$b\\leftarrow b -\\eta\\left[\\frac{\\partial{L(w^Tx_i + b, y_i)}}{\\partial{b}}\\right]$\n",
    "\n",
    "На более понятном языке это можно выразить так:\n",
    "1. Вычислите значение линейной функции для $x_i$ объекта;\n",
    "2. Вычислите градиент функции потерь (часть этого уже готова в предыдущем пункте);\n",
    "3. Обновите параметры модели $w$ и $b$ (`weights` и `intercept`). Не забудьте про learning rate.\n",
    "\n",
    "После того, как все покажется максимально понятным, реализуйте это в коде. Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*):\n",
    "\n",
    "`pytest test_sgd.py -k TestSgdFn -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exclusive-delivery",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 69 deselected / 4 selected                                \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestSgdFn::test_return_epochs_with_no_early_stopping \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "test_sgd.py::TestSgdFn::test_fit_only_weights \u001b[32mPASSED\u001b[0m\u001b[33m                     [ 50%]\u001b[0m\n",
      "test_sgd.py::TestSgdFn::test_fit_weights_fit_intercept \u001b[32mPASSED\u001b[0m\u001b[33m            [ 75%]\u001b[0m\n",
      "test_sgd.py::TestSgdFn::test_fit_given_weights \u001b[32mPASSED\u001b[0m\u001b[33m                    [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "test_sgd.py::TestSgdFn::test_return_epochs_with_no_early_stopping\n",
      "test_sgd.py::TestSgdFn::test_fit_only_weights\n",
      "test_sgd.py::TestSgdFn::test_fit_weights_fit_intercept\n",
      "test_sgd.py::TestSgdFn::test_fit_given_weights\n",
      "  /home/maksim/miniconda3/envs/mlngu/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "  \n",
      "      The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "      the documentation of this function for further details.\n",
      "  \n",
      "      The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "      dataset unless the purpose of the code is to study and educate about\n",
      "      ethical issues in data science and machine learning.\n",
      "  \n",
      "      In this special case, you can fetch the dataset from the original\n",
      "      source::\n",
      "  \n",
      "          import pandas as pd\n",
      "          import numpy as np\n",
      "  \n",
      "  \n",
      "          data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "          raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "          data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "          target = raw_df.values[1::2, 2]\n",
      "  \n",
      "      Alternative datasets include the California housing dataset (i.e.\n",
      "      :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "      dataset. You can load the datasets as follows::\n",
      "  \n",
      "          from sklearn.datasets import fetch_california_housing\n",
      "          housing = fetch_california_housing()\n",
      "  \n",
      "      for the California housing dataset and::\n",
      "  \n",
      "          from sklearn.datasets import fetch_openml\n",
      "          housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "  \n",
      "      for the Ames housing dataset.\n",
      "      \n",
      "    warnings.warn(msg, category=FutureWarning)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m================ \u001b[32m4 passed\u001b[0m, \u001b[33m\u001b[1m69 deselected\u001b[0m, \u001b[33m\u001b[1m4 warnings\u001b[0m\u001b[33m in 14.27s\u001b[0m\u001b[33m =================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestSgdFn -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-rough",
   "metadata": {},
   "source": [
    "# SGDRegressor (2 балла)\n",
    "\n",
    "После того, как мы написали ядро модели, напишем и обертку, подражая интерфейсу `sklearn.linear_model.SGDRegressor`. Для начала стоит определить конструктор класса, который принимает параметры `loss`, `fit_intercept`, `max_iter` и `eta0`. Обратите внимание, что для удобства лосс функцию нужно передавать строкой, а на основании этого решать, какой класс для ее вычисления использовать.\n",
    "\n",
    "Обратите внимание, что все таким классы имеют по умолчанию значения для ***всех*** параметров. Это нужно, чтобы с таким интерфейсом было удобно работать из коробки, в несколько секунд создавая модель:\n",
    "\n",
    "`reg = SGDRegressor()`\n",
    "\n",
    "Это удобно, ведь мы можем каждый раз переопределять только те параметры, которые нам нужны. По для значения `fit_intercept` по умолчанию нужно выставить `True`, для `max_iter` -- тысячу, а для `eta0` -- одну сотую.\n",
    "\n",
    "Интерфейс практически любой модели машинного обучения с учителем в `scikit-learn` имеет два главных метода:  \n",
    "`fit(X, y)` -- принимает матрицу объекты-признаки и вектор таргетов тренировочной выборки, запускает процесс обучения;  \n",
    "`predict(X)` -- принимает матрицy объекты-признаки тестовой выборки, выдает предсказания для полученных объектов. \n",
    "\n",
    "В этой части нужно будет реализовать методы конструктор класса, а также методы `fit` и `predict`. Задача тут стоит простая -- инициализировать параметры модели и передать их в уже готовый написанный метод `sgd`. Цель всего этого -- просто понять, как разделяется ответственность между функцией с алгоритмом и обвязкой в виде класса.\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*):\n",
    "\n",
    "`pytest test_sgd.py -k TestSGDRegressor -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "impossible-headquarters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 66 deselected / 7 selected                                \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestSGDRegressor::test_validate_loss \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 14%]\u001b[0m\n",
      "test_sgd.py::TestSGDRegressor::test_validate_max_iter \u001b[32mPASSED\u001b[0m\u001b[32m             [ 28%]\u001b[0m\n",
      "test_sgd.py::TestSGDRegressor::test_coef_attribute \u001b[32mPASSED\u001b[0m\u001b[32m                [ 42%]\u001b[0m\n",
      "test_sgd.py::TestSGDRegressor::test_intercept_attribute \u001b[32mPASSED\u001b[0m\u001b[32m           [ 57%]\u001b[0m\n",
      "test_sgd.py::TestSGDRegressor::test_fit_only_weights \u001b[32mPASSED\u001b[0m\u001b[32m              [ 71%]\u001b[0m\n",
      "test_sgd.py::TestSGDRegressor::test_fit_weights_fit_intercept \u001b[32mPASSED\u001b[0m\u001b[33m     [ 85%]\u001b[0m\n",
      "test_sgd.py::TestSGDRegressor::test_predict \u001b[33mSKIPPED\u001b[0m (not implemented)\u001b[33m    [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "test_sgd.py::TestSGDRegressor::test_fit_only_weights\n",
      "test_sgd.py::TestSGDRegressor::test_fit_weights_fit_intercept\n",
      "  /home/maksim/miniconda3/envs/mlngu/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "  \n",
      "      The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "      the documentation of this function for further details.\n",
      "  \n",
      "      The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "      dataset unless the purpose of the code is to study and educate about\n",
      "      ethical issues in data science and machine learning.\n",
      "  \n",
      "      In this special case, you can fetch the dataset from the original\n",
      "      source::\n",
      "  \n",
      "          import pandas as pd\n",
      "          import numpy as np\n",
      "  \n",
      "  \n",
      "          data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "          raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "          data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "          target = raw_df.values[1::2, 2]\n",
      "  \n",
      "      Alternative datasets include the California housing dataset (i.e.\n",
      "      :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "      dataset. You can load the datasets as follows::\n",
      "  \n",
      "          from sklearn.datasets import fetch_california_housing\n",
      "          housing = fetch_california_housing()\n",
      "  \n",
      "      for the California housing dataset and::\n",
      "  \n",
      "          from sklearn.datasets import fetch_openml\n",
      "          housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "  \n",
      "      for the Ames housing dataset.\n",
      "      \n",
      "    warnings.warn(msg, category=FutureWarning)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m=========== \u001b[32m6 passed\u001b[0m, \u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m66 deselected\u001b[0m, \u001b[33m\u001b[1m2 warnings\u001b[0m\u001b[33m in 5.13s\u001b[0m\u001b[33m ============\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestSGDRegressor -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-congo",
   "metadata": {},
   "source": [
    "Если все тесты проходят, то вы справились с этой задачей. Поздравляю, вы написали свою первую модель машинного обучения руками с нуля, а это все-таки нетривиальная задачка."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-dance",
   "metadata": {},
   "source": [
    "# Взрыв градиента (gradient explosion) (0.5 балла)\n",
    "\n",
    "Давайте испробуем нашу самописную модель на реальных данных и поглядим, как оптимизируются веса модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stopped-definition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maksim/PycharmProjects/twinkle/03-sgd/_sgd.py:43: RuntimeWarning: overflow encountered in multiply\n",
      "  dp_dw = (y_hat - y[i])*X[i]*sample_weight[i] if sample_weight is not None else (y_hat - y[i])*X[i]\n",
      "/home/maksim/PycharmProjects/twinkle/03-sgd/_sgd.py:43: RuntimeWarning: invalid value encountered in multiply\n",
      "  dp_dw = (y_hat - y[i])*X[i]*sample_weight[i] if sample_weight is not None else (y_hat - y[i])*X[i]\n",
      "/home/maksim/PycharmProjects/twinkle/03-sgd/_sgd.py:45: RuntimeWarning: invalid value encountered in subtract\n",
      "  weights = weights - eta*dp_dw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from SGDRegressor import SGDRegressor\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "reg = SGDRegressor().fit(X, y)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-participation",
   "metadata": {},
   "source": [
    "Огонь! Не переживайте, если вы увидите здесь вектор `nan` (а вы его здесь увидите). Если тесты прошли -- вы все сделали правильно,поэтому давайте подумаем, как мы пришли к жизни такой. Для этого посмотрим, как изменяются веса в зависимости от количества пройденных эпох.\n",
    "\n",
    "*Кстати, если вам повезет, то вы увидите красное предупреждение о недопустимом значении при умножении в вычислении весов.*\n",
    "\n",
    "Для удобства отладки добавим еще один булев параметр в класс `SGDRegressor`, а называется он `verbose`. Он будет отвечать за *многословность* нашей модели, и в verbose-режиме модель будет выдавать отладочную информацию. Этот же параметр прокиньте в функцию `sgd`, благо там он уже есть, и даже есть пример его использования.\n",
    "\n",
    "После этого добавьте отладочный вывод градиента `dloss` на каждом ***объекте*** при включенном параметре `verbose` (не забудьте передать его в вызове `sgd` внутри метода `fit`). Для этого воспользуйтесь заготовкой функции `print_dloss` в том же файле `_sgd.py`. Чтобы не выводить пачку лишних nan, добавьте в функции условие проверку на nan наравне с `verbose`. Здесь вам предстоит потренироваться в сложнейшем написании условия и форматированном выводе питона, чтобы все выглядело красиво.\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*):\n",
    "\n",
    "`pytest test_sgd.py -k TestPrintDloss -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "native-original",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 65 deselected / 8 selected                                \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestPrintDloss::test_no_verbose \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 12%]\u001b[0m\n",
      "test_sgd.py::TestPrintDloss::test_nan \u001b[32mPASSED\u001b[0m\u001b[32m                             [ 25%]\u001b[0m\n",
      "test_sgd.py::TestPrintDloss::test_zero \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 37%]\u001b[0m\n",
      "test_sgd.py::TestPrintDloss::test_positive1 \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 50%]\u001b[0m\n",
      "test_sgd.py::TestPrintDloss::test_positive2 \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 62%]\u001b[0m\n",
      "test_sgd.py::TestPrintDloss::test_positive3 \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 75%]\u001b[0m\n",
      "test_sgd.py::TestPrintDloss::test_negative \u001b[32mPASSED\u001b[0m\u001b[32m                        [ 87%]\u001b[0m\n",
      "test_sgd.py::TestPrintDloss::test_inside_sgd_no_verbose \u001b[33mSKIPPED\u001b[0m (not...)\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m================= \u001b[32m\u001b[1m7 passed\u001b[0m, \u001b[33m1 skipped\u001b[0m, \u001b[33m65 deselected\u001b[0m\u001b[32m in 0.59s\u001b[0m\u001b[32m ==================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestPrintDloss -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-azerbaijan",
   "metadata": {},
   "source": [
    "Ну а теперь еще разок запустим обучение на одну эпоху и включенным параметром `verbose`:\n",
    "\n",
    "*Подсказка: если выводятся только номера эпох, а градиентов нет -- перезапустите тетрадку: сверху в меню Kernel: Resart.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "undefined-central",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "-- grad -7.60e+02\n",
      "-- grad +1.70e+06\n",
      "-- grad -3.71e+09\n",
      "-- grad +6.27e+12\n",
      "-- grad -9.84e+15\n",
      "-- grad +2.88e+19\n",
      "-- grad -1.02e+23\n",
      "-- grad +2.18e+26\n",
      "-- grad -6.77e+29\n",
      "-- grad +2.48e+33\n",
      "-- grad -6.68e+36\n",
      "-- grad +1.65e+40\n",
      "-- grad -3.85e+43\n",
      "-- grad +8.42e+46\n",
      "-- grad -1.88e+50\n",
      "-- grad +7.11e+53\n",
      "-- grad -2.55e+57\n",
      "-- grad +6.34e+60\n",
      "-- grad -1.41e+64\n",
      "-- grad +3.08e+67\n",
      "-- grad -7.51e+70\n",
      "-- grad +2.02e+74\n",
      "-- grad -4.98e+77\n",
      "-- grad +1.27e+81\n",
      "-- grad -3.45e+84\n",
      "-- grad +6.41e+87\n",
      "-- grad -1.35e+91\n",
      "-- grad +6.49e+94\n",
      "-- grad -2.69e+98\n",
      "-- grad +6.71e+101\n",
      "-- grad -1.68e+105\n",
      "-- grad +4.33e+108\n",
      "-- grad -1.55e+112\n",
      "-- grad +5.37e+115\n",
      "-- grad -1.86e+119\n",
      "-- grad +8.58e+122\n",
      "-- grad -2.68e+126\n",
      "-- grad +6.82e+129\n",
      "-- grad -1.68e+133\n",
      "-- grad +4.21e+136\n",
      "-- grad -1.02e+140\n",
      "-- grad +2.38e+143\n",
      "-- grad -6.02e+146\n",
      "-- grad +1.37e+150\n",
      "-- grad -2.10e+153\n",
      "-- grad +9.83e+156\n",
      "-- grad -4.26e+160\n",
      "-- grad +1.45e+164\n",
      "-- grad -3.40e+167\n",
      "-- grad +7.48e+170\n",
      "-- grad -1.65e+174\n",
      "-- grad +4.82e+177\n",
      "-- grad -1.45e+181\n",
      "-- grad +3.25e+184\n",
      "-- grad -8.07e+187\n",
      "-- grad +1.96e+191\n",
      "-- grad -6.93e+194\n",
      "-- grad +2.31e+198\n",
      "-- grad -7.95e+201\n",
      "-- grad +2.36e+205\n",
      "-- grad -4.49e+208\n",
      "-- grad +9.93e+211\n",
      "-- grad -2.17e+215\n",
      "-- grad +6.68e+218\n",
      "-- grad -1.92e+222\n",
      "-- grad +4.70e+225\n",
      "-- grad -1.15e+229\n",
      "-- grad +2.44e+232\n",
      "-- grad -6.14e+235\n",
      "-- grad +1.77e+239\n",
      "-- grad -4.75e+242\n",
      "-- grad +1.12e+246\n",
      "-- grad -3.10e+249\n",
      "-- grad +7.99e+252\n",
      "-- grad -1.66e+256\n",
      "-- grad +3.70e+259\n",
      "-- grad -1.10e+263\n",
      "-- grad +3.13e+266\n",
      "-- grad -7.28e+269\n",
      "-- grad +1.67e+273\n",
      "-- grad -5.62e+276\n",
      "-- grad +2.02e+280\n",
      "-- grad -5.09e+283\n",
      "-- grad +1.79e+287\n",
      "-- grad -7.15e+290\n",
      "-- grad +3.03e+294\n",
      "-- grad -8.95e+297\n",
      "-- grad +2.61e+301\n",
      "-- grad -9.50e+304\n",
      "-- grad +inf\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n",
      "-- grad nan\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from SGDRegressor import SGDRegressor\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "reg = SGDRegressor(max_iter=1, verbose=True).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-upset",
   "metadata": {},
   "source": [
    "А теперь посмотрите на значения градиента и напишите ниже ответы на несколько вопросов:\n",
    "* Как изменяется значение градиента?\n",
    "* Какое последнее значение лосса выведено, до того как стало `nan`?\n",
    "* Что просходит с весами при таких значениях градиента?\n",
    "* Почему происходит взрыв градиента?\n",
    "* Как бороться с этим взрывом?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-taiwan",
   "metadata": {},
   "source": [
    "* Меняет знак\n",
    "* -4.95e+306\n",
    "* Уходят в бесконечность\n",
    "* Признаки разные порядков\n",
    "* Масштабирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-footwear",
   "metadata": {},
   "source": [
    "# Масштабирование признаков (5 баллов)\n",
    "\n",
    "## MaxAbsScaler (1 балл)\n",
    "\n",
    "Как мы уже поняли, недостатком нашего алгоритма является чувствительность к масштабированию признаков. Немасштабированные признаки могут иметь огромные значения от минус до плюс бесконечности. Самый простой способ уменьшить их разброс -- найти максимальное значение каждого признака среди всех объектов, запомнить его, после чего разделить значение каждого признака на это максимальное значение. После этого значения признаков будет в диапазоне $[-1.0, 1.0]$, а максимальное абсолютное значение каждого признака не будет превышать $1.0$.\n",
    "\n",
    "Реализуйте эту логику в классе `MaxAbsScaler`, заготовку которого можно найти в файле `MaxAbsScaler.py`. Что делают тесты:\n",
    "1. `test_fit_chainable` проверяет, что метод `fit` возвращает указатель на сам объект модели;\n",
    "2. `test_fit_n_samples_seen` проверяет, что вызов `fit` записывает в атрибут `n_samples_seen_` объекта модели количество объектов в обучающей выборке;\n",
    "3. `test_fit_max_abs_*` проверяют, что метод `fit` записывает в атрибут `max_abs_` вектор максимальных по модулю значений каждого признака;\n",
    "4. `test_fit_scale_*` проверяют, что метод `fit` записывает в атрибут `scale_` вектор масштабов для приведения признаков в диапазон $[-1.0, 1.0]$. В дальнейшем этот вектор поэлементно домножается на вектор признаков, который мы хотим отмасштабировать;\n",
    "5. `test_transform_*` проверяют, что метод `transform`, верно масштабирует матрицу объектов на входе с помощью обученных параметров скейлера;\n",
    "5. `test_fit_transform_*` проверяют, что метод `fit_transform` работает одновременно и как `fit` (обучает параметры модели), и как `transform` (преобразует входные данные).\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestMaxAbsScaler -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "southern-temple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 63 deselected / 10 selected                               \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_chainable \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 10%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_n_samples_seen \u001b[32mPASSED\u001b[0m\u001b[32m            [ 20%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_max_abs_easy \u001b[32mPASSED\u001b[0m\u001b[32m              [ 30%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_max_abs_from_docs \u001b[32mPASSED\u001b[0m\u001b[32m         [ 40%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_scale_easy \u001b[32mPASSED\u001b[0m\u001b[32m                [ 50%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_scale_from_docs \u001b[32mPASSED\u001b[0m\u001b[32m           [ 60%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_transform_easy \u001b[32mPASSED\u001b[0m\u001b[32m                [ 70%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_transform_from_docs \u001b[32mPASSED\u001b[0m\u001b[32m           [ 80%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_transform_easy \u001b[32mPASSED\u001b[0m\u001b[32m            [ 90%]\u001b[0m\n",
      "test_sgd.py::TestMaxAbsScaler::test_fit_transform_from_docs \u001b[32mPASSED\u001b[0m\u001b[32m       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m====================== \u001b[32m\u001b[1m10 passed\u001b[0m, \u001b[33m63 deselected\u001b[0m\u001b[32m in 0.59s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestMaxAbsScaler -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-queue",
   "metadata": {},
   "source": [
    "Давайте попробуем воспользоваться нашим скейлером, чтобы решить задачу регрессии на тех же данных, что и раньше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "charming-blank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.275884  ,  4.50347168, -1.49808335,  2.68848854,  2.25574396,\n",
       "        7.17742612,  0.4795809 ,  4.18624003, -2.44051075, -0.53361557,\n",
       "        3.45940077,  8.06658573, -2.91344649])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from MaxAbsScaler import MaxAbsScaler\n",
    "from SGDRegressor import SGDRegressor\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X = MaxAbsScaler().fit_transform(X)\n",
    "reg = SGDRegressor(max_iter=1).fit(X, y)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-essence",
   "metadata": {},
   "source": [
    "Работает ли теперь наша модель и взрываются ли веса? Почему? Напишите, что вы думаете об этом:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-leisure",
   "metadata": {},
   "source": [
    "Работает, веса не взрываются, поскольку признаки одинаковых порядков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-grass",
   "metadata": {},
   "source": [
    "## Метрики качества регрессии: MAE и MSE (1 балл)\n",
    "\n",
    "Теперь, когда все хоть как-то работает, стоит измерить качество модели. Для этого воспользуемся всем известными средней абсолютной и квадратичной ошибками, измерять которые будем на отложенной выборке.\n",
    "\n",
    "Реализуйте эти две метрики в файле `metrics.py` в соответствующих заготовках функций `mean_absolute_error` и `mean_squared_error`. Что делают тесты:\n",
    "1. `test_absolute_easy` проверяет, что функция `mean_absolute_error` работает корректно;\n",
    "1. `test_squared_easy` проверяет, что функция `mean_squared_error` работает корректно;\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestMetrics -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "checked-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 71 deselected / 2 selected                                \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestMetrics::test_absolute_easy \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 50%]\u001b[0m\n",
      "test_sgd.py::TestMetrics::test_squared_easy \u001b[32mPASSED\u001b[0m\u001b[32m                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m71 deselected\u001b[0m\u001b[32m in 0.60s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestMetrics -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-trigger",
   "metadata": {},
   "source": [
    "Разбейте выборку на трейн и тест, обучите модель на трейне с параметрами по умолчанию, получите предсказания на тестовой выборке. Посчитайте метрики на отложенной выборке, выведите их значения.\n",
    "\n",
    "*Подсказка: после этого заверните все это в функцию с одним параметром, через который в нее можно передать объект скейлера. Она нам еще пригодится.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "answering-comedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 57.38077724144307\n",
      "MAE = 5.267689670344145\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def model_scale(X, y, scaler=False):\n",
    "    if scaler:\n",
    "        print(\"SCALED with\", scaler)\n",
    "        X = scaler().fit_transform(X)\n",
    "  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    reg = SGDRegressor(max_iter=1).fit(X_train, y_train)\n",
    "    prediction = reg.predict(X_test)\n",
    "    mse = mean_squared_error(prediction, y_test)\n",
    "    mae = mean_absolute_error(prediction, y_test)\n",
    "    print(f\"MSE = {mse}\\nMAE = {mae}\\n\\n\")\n",
    "model_scale(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-permit",
   "metadata": {},
   "source": [
    "Напишите ниже ответы на следующие вопросы:\n",
    "* Что вы думаете о полученных значениях?\n",
    "* Много это или мало, хорошо или плохо?\n",
    "* На чем лучше фитить скейлер: на всем датасете или только на трейне?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f789246e-91f1-4a26-b09d-5d42bc86cdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.532806324110677"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-skill",
   "metadata": {},
   "source": [
    "* Кажется, довольно большая ошибка\n",
    "* Лучше скейлить весь датасет "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-halloween",
   "metadata": {},
   "source": [
    "## MinMaxScaler (1 балл)\n",
    "\n",
    "Предыдущий способ масштабирования работает, и работает относительно неплохо -- по крайней мере модель как-то обучается. Хорошо она обучается или плохо мы посмотрим чуть позже, а пока займемся написанием еще пары классов для маcштабирования признаков.\n",
    "\n",
    "`MinMaxScaler` масштабирует признаки в заданный диапазон значений `[min, max]`, по умолчанию это `[0, 1]`, который передается как параметр конструктора -- `feature_range`. Работает скейлер весьма просто. Для начала нужно найти масштаб: взять разность между максимальным и минимальным значениями диапазона, в который мы масштабируем (`feature_range`), а потом разделить её на разность максимального и минимального значений по каждому признаку. После этого нужно отмасштабировать минимальные значения каждого признака и вычесть их из начала заданного диапазона, в который мы масштабируем. Потом для преобразования данных мы просто должны умножить каждый признак на масштаб и прибавить к нему минимальные значения из предыдущего шага.\n",
    "\n",
    "Реализуйте эту логику в классе `MinMaxScaler`, заготовку которого можно найти в файле `MinMaxScaler.py`. Что делают тесты:\n",
    "1. `test_fit_chainable` проверяет, что метод `fit` возвращает указатель на сам объект модели;\n",
    "2. `test_fit_n_samples_seen` проверяет, что вызов `fit` записывает в атрибут `n_samples_seen_` объекта модели количество объектов в обучающей выборке;\n",
    "3. `test_fit_data_min` проверяет, что метод `fit` записывает в атрибут `data_min_` вектор минимальных значений каждого признака;\n",
    "4. `test_fit_data_max` проверяет, что метод `fit` записывает в атрибут `data_max_` вектор максимальных значений каждого признака;\n",
    "5. `test_fit_data_range` проверяет, что метод `fit` записывает в атрибут `data_range_` вектор разницы между максимальными и минимальными значениями каждого признака, см. пункты выше;\n",
    "6. `test_fit_scale` проверяет, что метод `fit` записывает в атрибут `scale_` масштаб для каждого признака. Он вычисляется как отношение разницы максимального и минимального значений данного диапазона `feature_range` из конструктора к разбросу значений на данных из предыдущего пункта. *Подсказка: если вам где-то захочется поделить на ноль, замените его единичкой*;\n",
    "7. `test_fit_min` проверяет, что метод `fit` записывает в атрибут `min_` вектор значений для корректировки к минимуму. Он вычисляется как разность минимального значения из диапазона `feature_range` и отмасштабированных минимальных значений каждого признака;\n",
    "8. `test_fit_in_feature_range` проверяет, что метод `fit` корректно работает при передаче диапазона значений, отличных от значений по умолчанию $[0, 1]$;\n",
    "9. `test_transform` проверяет, что метод `transform` корректно масштабирует данные, используя обученные параметры скейлера;\n",
    "10. `test_fit_transform` проверяет, что метод `fit_transform` корректно обучает параметры скейлера и корректно масштабирует полученные данные.\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestMinMaxScaler -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dried-packaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 63 deselected / 10 selected                               \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestMinMaxScaler::test_fit_chainable \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 10%]\u001b[0m\n",
      "test_sgd.py::TestMinMaxScaler::test_fit_n_samples_seen \u001b[32mPASSED\u001b[0m\u001b[32m            [ 20%]\u001b[0m\n",
      "test_sgd.py::TestMinMaxScaler::test_fit_data_min \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 30%]\u001b[0m\n",
      "test_sgd.py::TestMinMaxScaler::test_fit_data_max \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 40%]\u001b[0m\n",
      "test_sgd.py::TestMinMaxScaler::test_fit_data_range \u001b[32mPASSED\u001b[0m\u001b[32m                [ 50%]\u001b[0m\n",
      "test_sgd.py::TestMinMaxScaler::test_fit_scale \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 60%]\u001b[0m\n",
      "test_sgd.py::TestMinMaxScaler::test_fit_min \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 70%]\u001b[0m\n",
      "test_sgd.py::TestMinMaxScaler::test_fit_in_feature_range \u001b[32mPASSED\u001b[0m\u001b[32m          [ 80%]\u001b[0m\n",
      "test_sgd.py::TestMinMaxScaler::test_transform \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 90%]\u001b[0m\n",
      "test_sgd.py::TestMinMaxScaler::test_fit_transform \u001b[32mPASSED\u001b[0m\u001b[32m                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m====================== \u001b[32m\u001b[1m10 passed\u001b[0m, \u001b[33m63 deselected\u001b[0m\u001b[32m in 0.62s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestMinMaxScaler -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-poison",
   "metadata": {},
   "source": [
    "## StandardScaler (1 балл)\n",
    "\n",
    "К третьему скейлеру вы должны были задуматься над следующим вопросом: \"Зачем нам столько разных?\". Мы сравним их чуть позже, а пока давайте допишем последний. Он масштабирует признаки вычитая среднее и деля на стандартное отклонение по следующей формуле:\n",
    "\n",
    "$z = \\frac{(x - u)}{s}$, где $u$ это среднее значение признака по выборке, а $s$ это стандартное отклонение этого признака.\n",
    "\n",
    "Этот скейлер должен принимать два аргумента:  \n",
    "`with_mean` -- включает вычисление среднего, иначе среднее -- 0;  \n",
    "`with_std` -- включает вычисление стандартного отклонения, иначе отклонение -- 1.\n",
    "\n",
    "Реализуйте эту логику в классе `StandardScaler`, заготовку которого можно найти в файле `StandardScaler.py`. Что делают тесты:\n",
    "1. `test_fit_chainable` проверяет, что метод `fit` возвращает указатель на сам объект модели;\n",
    "2. `test_fit_n_samples_seen` проверяет, что вызов `fit` записывает в атрибут `n_samples_seen_` объекта модели количество объектов в обучающей выборке;\n",
    "3. `test_fit_mean` проверяет, что метод `fit` записывает в атрибут `mean_` вектор средних значений по каждому признаку;\n",
    "4. `test_fit_var` проверяет, что метод `fit` записывает в атрибут `var_` вектор стандартных отклонений по каждому признаку;\n",
    "5. `test_fit_var_without_std` проверяет, что метод `fit` записывает в атрибут `var_` значение `None` при выключенном флаге `with_std`;\n",
    "6. `test_fit_mean_var_without_mean_std` проверяет, что метод `fit` записывает в атрибуты `mean_` и `var_` значения `None` при выключенных флагах `with_mean` и `with_std`;\n",
    "7. `test_fit_scale` проверяет, что метод `fit` записывает в атрибут `scale_` вектор масштабов каждого признака;\n",
    "8. `test_fit_scale_without_std` проверяет, что метод `fit` записывает в атрибут `scale_` значение `None` при выключенном флаге `with_std`;\n",
    "9. `test_fit_scale_without_mean_std` проверяет, что метод `fit` записывает в атрибут `scale_` значение `None` при выключенных флагах `with_mean` и `with_std`;\n",
    "10. `test_transform` проверяет, что метод `transform` корректно масштабирует данные, используя обученные параметры скейлера;\n",
    "11. `test_transform_without_std` проверяет, что метод `transform` корректно масштабирует данные, используя обученные параметры скейлера (при выключенном параметре флаге `with_std`);\n",
    "12. `test_transform_without_mean_std` проверяет, что метод `transform` корректно масштабирует данные, используя обученные параметры скейлера (при выключенных флагах `with_mean` и `with_std`);\n",
    "13. `test_fit_transform` проверяет, что метод `fit_transform` корректно обучает параметры скейлера и корректно масштабирует полученные данные.\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestStandardScaler -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deadly-aruba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 60 deselected / 13 selected                               \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestStandardScaler::test_fit_chainable \u001b[32mPASSED\u001b[0m\u001b[32m               [  7%]\u001b[0m\n",
      "test_sgd.py::TestStandardScaler::test_fit_n_samples_seen \u001b[32mPASSED\u001b[0m\u001b[32m          [ 15%]\u001b[0m\n",
      "test_sgd.py::TestStandardScaler::test_fit_mean \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 23%]\u001b[0m\n",
      "test_sgd.py::TestStandardScaler::test_fit_var \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 30%]\u001b[0m\n",
      "test_sgd.py::TestStandardScaler::test_fit_var_without_std \u001b[32mPASSED\u001b[0m\u001b[32m         [ 38%]\u001b[0m\n",
      "test_sgd.py::TestStandardScaler::test_fit_mean_var_without_mean_std \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "test_sgd.py::TestStandardScaler::test_fit_scale \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 53%]\u001b[0m\n",
      "test_sgd.py::TestStandardScaler::test_fit_scale_without_std \u001b[32mPASSED\u001b[0m\u001b[32m       [ 61%]\u001b[0m\n",
      "test_sgd.py::TestStandardScaler::test_fit_scale_without_mean_std \u001b[32mPASSED\u001b[0m\u001b[32m  [ 69%]\u001b[0m\n",
      "test_sgd.py::TestStandardScaler::test_transform \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 76%]\u001b[0m\n",
      "test_sgd.py::TestStandardScaler::test_transform_without_std \u001b[32mPASSED\u001b[0m\u001b[32m       [ 84%]\u001b[0m\n",
      "test_sgd.py::TestStandardScaler::test_transform_without_mean_std \u001b[32mPASSED\u001b[0m\u001b[32m  [ 92%]\u001b[0m\n",
      "test_sgd.py::TestStandardScaler::test_fit_transform \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m====================== \u001b[32m\u001b[1m13 passed\u001b[0m, \u001b[33m60 deselected\u001b[0m\u001b[32m in 0.62s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestStandardScaler -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-providence",
   "metadata": {},
   "source": [
    "## Чем лучше масштабировать? (1 балл)\n",
    "\n",
    "Давайте сравним наши способы масштабировать признаки, обучив регрессор со всеми тремя алгоритмами. Вычислите MAE и MSE для каждого скейлера на тестовых данных, сравните их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alive-dealing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCALED with <class 'MinMaxScaler.MinMaxScaler'>\n",
      "MSE = 55.32783352598604\n",
      "MAE = 5.419377635858724\n",
      "\n",
      "\n",
      "SCALED with <class 'StandardScaler.StandardScaler'>\n",
      "MSE = 27.32460800735155\n",
      "MAE = 3.336798799196438\n",
      "\n",
      "\n",
      "SCALED with <class 'MaxAbsScaler.MaxAbsScaler'>\n",
      "MSE = 53.10457081045337\n",
      "MAE = 5.170841355783048\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from StandardScaler import StandardScaler\n",
    "from MinMaxScaler import MinMaxScaler\n",
    "from MaxAbsScaler import MaxAbsScaler\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "def model_scale(X, y, scaler=False):\n",
    "    if scaler:\n",
    "        print(\"SCALED with\", scaler)\n",
    "        X_scaled = scaler().fit_transform(X)\n",
    "    else:\n",
    "        X_scaled = X\n",
    "  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    reg = SGDRegressor(max_iter=1).fit(X_train, y_train)\n",
    "    prediction = reg.predict(X_test)\n",
    "    mse = mean_squared_error(prediction, y_test)\n",
    "    mae = mean_absolute_error(prediction, y_test)\n",
    "    print(f\"MSE = {mse}\\nMAE = {mae}\\n\\n\")\n",
    "    \n",
    "model_scale(X, y, scaler=MinMaxScaler)\n",
    "model_scale(X, y, scaler=StandardScaler)\n",
    "model_scale(X, y, scaler=MaxAbsScaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-andrews",
   "metadata": {},
   "source": [
    "Ответьте на следующие вопросы:\n",
    "* Сильно ли отличаются результаты?\n",
    "* Появился ли смысл в значениях средней абсолютной и квадратичной ошибок в рамках этой задачи?\n",
    "* Какой метод масштабирования работает лучше всех?\n",
    "* Какой хуже всех? Как вам кажется, почему?\n",
    "* Каким будете пользоваться в дальнейшем? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-elizabeth",
   "metadata": {},
   "source": [
    "* Довольно сильно\n",
    "* MSE больше штрафует за выбросы \n",
    "* StandardScaler\n",
    "* MaxAbsScaler и MinMaxScaler работают аналогично\n",
    "* Зависит от задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-issue",
   "metadata": {},
   "source": [
    "# Бонус: снова SGD (5 баллов)\n",
    "\n",
    "Настало время расширить наш игрушечный алгоритм, доведя его до ума. Для этого надо добавить еще несколько фич.\n",
    "\n",
    "## Случайный выбор объектов. Shuffle (1 балл)\n",
    "\n",
    "Пока что наша модель не совсем соответствует алгоритму стохастического градиентного спуска, ведь мы перебираем элементы всегда в одном и том же порядке. В этой части вам необходимо добавить случайность в выборе элементов внутри одной эпохи при условии, что каждый элемент будет выбран ровно один раз.\n",
    "\n",
    "Однако перемешивание элементов дело непростое, и для удобства тестирование должно быть воспроизводимым. Для этого нужно дополнительно передавать в модель зерно генератора псевдослучайных чисел. Добавьте в конструктор `SGDRegressor` булев параметр `shuffle` и сделайте его по умолчанию равным `True`. Еще добавьте целочисленный параметр `random_state`, равный по умолчанию `None`. После прокиньте их в функцию `sgd` внутри метода `fit`.\n",
    "\n",
    "Внутри `sgd` в зависимости от флага `shuffle` создавайте ГПСЧ с заданным зерном и добавьте случайный выбор следующего элемента. Зерно генератора случайных чисел соответствует параметру `seed` внутри функции `_sgd`. Помните, что каждый элемент должен поучаствовать в градиентном спуске один раз в каждой эпохе.\n",
    "\n",
    "*Подсказка: проще сначала написать реализацию в функции `sgd`, простестировать ее, и после прокинуть параметры снаружи из `SGDRegressor`.*\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestShuffle -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "quarterly-justice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 66 deselected / 7 selected                                \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestShuffle::test_sgd_every_item \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 14%]\u001b[0m\n",
      "test_sgd.py::TestShuffle::test_sgd_no_shuffle \u001b[32mPASSED\u001b[0m\u001b[33m                     [ 28%]\u001b[0m\n",
      "test_sgd.py::TestShuffle::test_sgd_with_given_seed \u001b[32mPASSED\u001b[0m\u001b[33m                [ 42%]\u001b[0m\n",
      "test_sgd.py::TestShuffle::test_sgd_with_empty_seed \u001b[32mPASSED\u001b[0m\u001b[33m                [ 57%]\u001b[0m\n",
      "test_sgd.py::TestShuffle::test_reg_no_shuffle \u001b[32mPASSED\u001b[0m\u001b[33m                     [ 71%]\u001b[0m\n",
      "test_sgd.py::TestShuffle::test_reg_with_given_seed \u001b[32mPASSED\u001b[0m\u001b[33m                [ 85%]\u001b[0m\n",
      "test_sgd.py::TestShuffle::test_reg_with_empty_seed \u001b[32mPASSED\u001b[0m\u001b[33m                [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "test_sgd.py: 16 warnings\n",
      "  /home/maksim/miniconda3/envs/mlngu/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "  \n",
      "      The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "      the documentation of this function for further details.\n",
      "  \n",
      "      The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "      dataset unless the purpose of the code is to study and educate about\n",
      "      ethical issues in data science and machine learning.\n",
      "  \n",
      "      In this special case, you can fetch the dataset from the original\n",
      "      source::\n",
      "  \n",
      "          import pandas as pd\n",
      "          import numpy as np\n",
      "  \n",
      "  \n",
      "          data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "          raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "          data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "          target = raw_df.values[1::2, 2]\n",
      "  \n",
      "      Alternative datasets include the California housing dataset (i.e.\n",
      "      :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "      dataset. You can load the datasets as follows::\n",
      "  \n",
      "          from sklearn.datasets import fetch_california_housing\n",
      "          housing = fetch_california_housing()\n",
      "  \n",
      "      for the California housing dataset and::\n",
      "  \n",
      "          from sklearn.datasets import fetch_openml\n",
      "          housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "  \n",
      "      for the Ames housing dataset.\n",
      "      \n",
      "    warnings.warn(msg, category=FutureWarning)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m================ \u001b[32m7 passed\u001b[0m, \u001b[33m\u001b[1m66 deselected\u001b[0m, \u001b[33m\u001b[1m16 warnings\u001b[0m\u001b[33m in 0.70s\u001b[0m\u001b[33m =================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestShuffle -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-thought",
   "metadata": {},
   "source": [
    "## Дообучение модели. Partial fit (1 балл)\n",
    "\n",
    "В `scikit-learn` некоторые модели включают в себя себя следующий метод:\n",
    "\n",
    "`partial_fit(X, y)` -- принимает матрицу объекты-признаки и вектор таргетов, обновляет веса модели, проходя градиентным спуском по новой пачке данных. Внутри этот метод реализуется как тот же `fit`, только не обнуляет веса *(параметры модели)* и прогоняет ***одну итерацию*** градиентного спуска по новым данным.\n",
    "\n",
    "В этой части реализуйте метод `partial_fit(X, y)`, который прогоняет одну эпоху градиентного спуска по своим аргументам, пользуясь уже обученными параметрами модели. Вы можете создать новый приватный метод `__partial_fit` (начинается с подчеркивания), который наравне с матрицей объекты-признаки и вектором таргетов принимает количество эпох. В него можно перетащить содержимое `fit`, а дальше уже использовать этот новый метод как внутри `fit` с (`max_iter=max_iter`), так и внутри `partial_fit` (c `max_iter=1`). Таким образом не придется делать два больших вызова `sgd` дважды.\n",
    "\n",
    "Реализуйте эту логику в классе `SGDRegressor`. Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestPartialFit -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "representative-laptop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 67 deselected / 6 selected                                \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestPartialFit::test_chainable \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 16%]\u001b[0m\n",
      "test_sgd.py::TestPartialFit::test_coef_shape \u001b[32mPASSED\u001b[0m\u001b[33m                      [ 33%]\u001b[0m\n",
      "test_sgd.py::TestPartialFit::test_intercept_shape \u001b[32mPASSED\u001b[0m\u001b[33m                 [ 50%]\u001b[0m\n",
      "test_sgd.py::TestPartialFit::test_runs_one_iter_only \u001b[32mPASSED\u001b[0m\u001b[33m              [ 66%]\u001b[0m\n",
      "test_sgd.py::TestPartialFit::test_use_fitted_weights \u001b[31mFAILED\u001b[0m\u001b[31m              [ 83%]\u001b[0m\n",
      "test_sgd.py::TestPartialFit::test_use_fitted_intercept \u001b[31mFAILED\u001b[0m\u001b[31m            [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m____________________ TestPartialFit.test_use_fitted_weights ____________________\u001b[0m\n",
      "\n",
      "self = <test_sgd.TestPartialFit object at 0x7f89ac512890>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_use_fitted_weights\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      "        X, y = load_dataset()\n",
      "        reg = SGDRegressor(fit_intercept=\u001b[94mFalse\u001b[39;49;00m, max_iter=\u001b[94m999\u001b[39;49;00m, shuffle=\u001b[94mFalse\u001b[39;49;00m).fit(X, y)\n",
      "        \u001b[94mfor\u001b[39;49;00m _ \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[94m1\u001b[39;49;00m):\n",
      "            reg.partial_fit(X, y)\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mreg.intercept_ = \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, reg.intercept_)\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mreg.coef_ = \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, reg.coef_)\n",
      "    \n",
      "        \u001b[94massert\u001b[39;49;00m np.allclose(reg.intercept_, np.array([\u001b[94m0\u001b[39;49;00m]))\n",
      ">       \u001b[94massert\u001b[39;49;00m np.allclose(reg.coef_, np.array([\n",
      "            -\u001b[94m1.10\u001b[39;49;00m, -\u001b[94m4.82\u001b[39;49;00m, \u001b[94m3.81\u001b[39;49;00m, \u001b[94m5.40\u001b[39;49;00m, \u001b[94m7.04\u001b[39;49;00m, -\u001b[94m2.39\u001b[39;49;00m, \u001b[94m4.12\u001b[39;49;00m,\n",
      "            -\u001b[94m6.84\u001b[39;49;00m, -\u001b[94m0.67\u001b[39;49;00m,  \u001b[94m2.03\u001b[39;49;00m, \u001b[94m3.51\u001b[39;49;00m, \u001b[94m1.51\u001b[39;49;00m, -\u001b[94m7.37\u001b[39;49;00m,\n",
      "        ]), atol=\u001b[94m5e-2\u001b[39;49;00m)\n",
      "\u001b[1m\u001b[31mE       assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where False = <function allclose at 0x7f89d0953400>(array([-9.51255165e-01, -5.36915481e+00,  4.50412820e+00,  5.63533933e+00,\\n        5.90931689e+00, -1.00224619e+00,  3.37825088e+00, -6.16184041e+00,\\n        1.84409793e-03,  1.29373251e+00,  3.11487506e+00,  1.83110666e+00,\\n       -4.84210641e+00]), array([-1.1 , -4.82,  3.81,  5.4 ,  7.04, -2.39,  4.12, -6.84, -0.67,\\n        2.03,  3.51,  1.51, -7.37]), atol=0.05)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where <function allclose at 0x7f89d0953400> = np.allclose\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    and   array([-9.51255165e-01, -5.36915481e+00,  4.50412820e+00,  5.63533933e+00,\\n        5.90931689e+00, -1.00224619e+00,  3.37825088e+00, -6.16184041e+00,\\n        1.84409793e-03,  1.29373251e+00,  3.11487506e+00,  1.83110666e+00,\\n       -4.84210641e+00]) = <SGDRegressor.SGDRegressor object at 0x7f89ac54cd30>.coef_\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    and   array([-1.1 , -4.82,  3.81,  5.4 ,  7.04, -2.39,  4.12, -6.84, -0.67,\\n        2.03,  3.51,  1.51, -7.37]) = <built-in function array>([-1.1, -4.82, 3.81, 5.4, 7.04, -2.39, ...])\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +      where <built-in function array> = np.array\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_sgd.py\u001b[0m:914: AssertionError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "reg.intercept_ =  [0]\n",
      "reg.coef_ =  [-9.51255165e-01 -5.36915481e+00  4.50412820e+00  5.63533933e+00\n",
      "  5.90931689e+00 -1.00224619e+00  3.37825088e+00 -6.16184041e+00\n",
      "  1.84409793e-03  1.29373251e+00  3.11487506e+00  1.83110666e+00\n",
      " -4.84210641e+00]\n",
      "\u001b[31m\u001b[1m___________________ TestPartialFit.test_use_fitted_intercept ___________________\u001b[0m\n",
      "\n",
      "self = <test_sgd.TestPartialFit object at 0x7f89ac54ca60>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_use_fitted_intercept\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      "        X, y = load_dataset()\n",
      "        reg = SGDRegressor(max_iter=\u001b[94m999\u001b[39;49;00m, shuffle=\u001b[94mFalse\u001b[39;49;00m).fit(X, y)\n",
      "        \u001b[94mfor\u001b[39;49;00m _ \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(\u001b[94m1\u001b[39;49;00m):\n",
      "            reg.partial_fit(X, y)\n",
      "    \n",
      ">       \u001b[94massert\u001b[39;49;00m np.allclose(reg.coef_, np.array([\n",
      "            -\u001b[94m1.16\u001b[39;49;00m, \u001b[94m0.65\u001b[39;49;00m, \u001b[94m0.21\u001b[39;49;00m, \u001b[94m1.31\u001b[39;49;00m, -\u001b[94m1.96\u001b[39;49;00m, \u001b[94m0.71\u001b[39;49;00m, -\u001b[94m0.23\u001b[39;49;00m,\n",
      "            -\u001b[94m2.13\u001b[39;49;00m, \u001b[94m1.97\u001b[39;49;00m, -\u001b[94m1.41\u001b[39;49;00m, -\u001b[94m1.37\u001b[39;49;00m, \u001b[94m0.27\u001b[39;49;00m, -\u001b[94m4.48\u001b[39;49;00m,\n",
      "        ]), atol=\u001b[94m5e-2\u001b[39;49;00m)\n",
      "\u001b[1m\u001b[31mE       assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where False = <function allclose at 0x7f89d0953400>(array([-0.76307021, -1.4941163 ,  1.74745996,  3.23588849,  2.61562788,\\n        0.80209282,  1.20629089, -1.89837588, -1.02188938, -0.49819079,\\n        0.3418583 ,  0.82102899, -4.24795492]), array([-1.16,  0.65,  0.21,  1.31, -1.96,  0.71, -0.23, -2.13,  1.97,\\n       -1.41, -1.37,  0.27, -4.48]), atol=0.05)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where <function allclose at 0x7f89d0953400> = np.allclose\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    and   array([-0.76307021, -1.4941163 ,  1.74745996,  3.23588849,  2.61562788,\\n        0.80209282,  1.20629089, -1.89837588, -1.02188938, -0.49819079,\\n        0.3418583 ,  0.82102899, -4.24795492]) = <SGDRegressor.SGDRegressor object at 0x7f89ac511750>.coef_\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    and   array([-1.16,  0.65,  0.21,  1.31, -1.96,  0.71, -0.23, -2.13,  1.97,\\n       -1.41, -1.37,  0.27, -4.48]) = <built-in function array>([-1.16, 0.65, 0.21, 1.31, -1.96, 0.71, ...])\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +      where <built-in function array> = np.array\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_sgd.py\u001b[0m:925: AssertionError\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "test_sgd.py::TestPartialFit::test_chainable\n",
      "test_sgd.py::TestPartialFit::test_coef_shape\n",
      "test_sgd.py::TestPartialFit::test_intercept_shape\n",
      "test_sgd.py::TestPartialFit::test_runs_one_iter_only\n",
      "test_sgd.py::TestPartialFit::test_use_fitted_weights\n",
      "test_sgd.py::TestPartialFit::test_use_fitted_intercept\n",
      "  /home/maksim/miniconda3/envs/mlngu/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "  \n",
      "      The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "      the documentation of this function for further details.\n",
      "  \n",
      "      The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "      dataset unless the purpose of the code is to study and educate about\n",
      "      ethical issues in data science and machine learning.\n",
      "  \n",
      "      In this special case, you can fetch the dataset from the original\n",
      "      source::\n",
      "  \n",
      "          import pandas as pd\n",
      "          import numpy as np\n",
      "  \n",
      "  \n",
      "          data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "          raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "          data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "          target = raw_df.values[1::2, 2]\n",
      "  \n",
      "      Alternative datasets include the California housing dataset (i.e.\n",
      "      :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "      dataset. You can load the datasets as follows::\n",
      "  \n",
      "          from sklearn.datasets import fetch_california_housing\n",
      "          housing = fetch_california_housing()\n",
      "  \n",
      "      for the California housing dataset and::\n",
      "  \n",
      "          from sklearn.datasets import fetch_openml\n",
      "          housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "  \n",
      "      for the Ames housing dataset.\n",
      "      \n",
      "    warnings.warn(msg, category=FutureWarning)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "=========================== short test summary info ============================\n",
      "FAILED test_sgd.py::TestPartialFit::test_use_fitted_weights - assert False\n",
      "FAILED test_sgd.py::TestPartialFit::test_use_fitted_intercept - assert False\n",
      "\u001b[31m============ \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[32m4 passed\u001b[0m, \u001b[33m67 deselected\u001b[0m, \u001b[33m6 warnings\u001b[0m\u001b[31m in 5.14s\u001b[0m\u001b[31m ============\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestPartialFit -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-recorder",
   "metadata": {},
   "source": [
    "## Горячий старт. Warm start (1 балл)\n",
    "\n",
    "Иногда обучение модели занимает достаточно очень много времени. Представим ситуацию: мы подбираем гиперпараметры модели, и на каждом этапе не очень то хочется учить модель с нуля, ведь нам достаточно обучить одну модель, а все остальные начинать обучать уже не с начала, а используя параметры обученной модели. С такой же ситуацией можно столкнуться, когда мы закончили обучение, но нам хочется прогнать еще сотню-другую эпох в надежде, что качество вырастет. Сейчас в нашей модели можем вызывать метод `fit` заново, но это приводит к паре проблем:\n",
    "1. Нет возможности выучить ту же модель на новых данных с нуля (со сбросом параметров к начальным);\n",
    "2. Нет возможности передать веса в модель перед обучением.\n",
    "\n",
    "Итак, хочется иметь возможность брать параметры обученной модели и передавать их в новую модель. Как же это можно сделать? Давайте добавим в конструктор булев параметр `warm_start` (по умолчанию `False`), и в зависимости от него будем решать, оставлять или сбрасывать параметры модели при перезапусках `fit`. Кроме того, нужно добавить в `fit` два параметра: `coef_init` и `intercept_init`, оба по умолчанию `None`. В них можно будет передать начальные значения весов и смещение.\n",
    "\n",
    "Алгоритм будет прост: если параметр `warm_start` включен, то при перезапуске `fit` мы пытаемся взять аргументы `coef_init` и `intercept_init` в качестве исходных значений весов и смещений. Если один из них пуст, то берем в качестве исходных уже готовые параметры нашей модели. Если `warm_start` выключен, то генерируем параметры заново, как мы уже делали до этого.\n",
    "\n",
    "Реализуйте эту логику в классе `SGDRegressor`. Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestWarmStart -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "equivalent-algebra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 72 deselected / 1 selected                                \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestWarmStart::test_disabled \u001b[33mSKIPPED\u001b[0m (not implemented)\u001b[33m      [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m====================== \u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m72 deselected\u001b[0m\u001b[33m in 0.59s\u001b[0m\u001b[33m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestWarmStart -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-strengthening",
   "metadata": {},
   "source": [
    "## Взвешивание объектов. Sample weights (1 балл)\n",
    "\n",
    "Иногда может оказаться, что не все объекты одинаково важны для обучения модели. Допустим у нас есть датасет с банковскими операциями, по которому мы должны научиться определять мошеннические операции. В этой выборке будут значительно преобладать законные операции, а мошеннических будет не так много (это кажется очевидным, если представить огромное количество операций в банке). Хочется сделать так, чтобы редко встречающиеся мошеннические операции помогали нам быстрее сдвигать градиент в нужную сторону, а значит и обучаться быстрее.\n",
    "\n",
    "Чтобы воспользоваться этим, хочется увеличить удельный вес таких редких объектов в выборке. Это можно сделать двумя путями: либо чаще показывать такие объекты, либо добавить число, которое характеризует вес каждого такого объекта в общей выборке.\n",
    "\n",
    "Здесь мы реализуем вторую идею с весам: добавим параметры `sample_weight` в методы `fit` и `partial_fit` (по умолчанию `None`), откуда будем передавать их в `sgd`. Внутри `sgd` же мы будем использовать вес каждого объекта, измненяя градиент на этом объекте пропорционально его весу.\n",
    "\n",
    "Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestSampleWeights -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "outstanding-pakistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 72 deselected / 1 selected                                \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestSampleWeights::test_no_weights \u001b[33mSKIPPED\u001b[0m (not impleme...)\u001b[33m [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m====================== \u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m72 deselected\u001b[0m\u001b[33m in 0.57s\u001b[0m\u001b[33m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestSampleWeights -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-carpet",
   "metadata": {},
   "source": [
    "## Коэффициент детерминации. $R^2$ (1 балл)\n",
    "\n",
    "Выше мы уже реализовали метрики MAE и MSE, но они страдают одной проблемой -- они неинтерпретируемы. Поправим это дело.\n",
    "\n",
    "У обертки реализуйте метод `score(X, y)`, который вычисляет коэффициент детерминации для своих аргументов. Вычисление должно происходить в два этапа: сначала внутри этого метода модель вычисляет предсказания для данного `X`, после чего вызывает функцию `r2_score`, которая вычисляет метрику на предсказанных значениях и таргетах.\n",
    "\n",
    "Для начала реализуйте метрику `r2_score`, заготовку которой можно найти в файле `metrics.py`. После этого реализуйте описанную выше логику в методе `score` класса `SGDRegressor`. Для проверки правильности своего решения запускайте тесты следующей командой (*и в ячейке ниже*): \n",
    "\n",
    "`pytest test_sgd.py -k TestR2Score -v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "nonprofit-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.4, pytest-7.1.1, pluggy-1.0.0 -- /home/maksim/miniconda3/envs/mlngu/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/maksim/PycharmProjects/twinkle/03-sgd\n",
      "plugins: anyio-3.5.0\n",
      "collected 73 items / 71 deselected / 2 selected                                \u001b[0m\u001b[1m\n",
      "\n",
      "test_sgd.py::TestR2Score::test_r2_score_set1 \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 50%]\u001b[0m\n",
      "test_sgd.py::TestR2Score::test_r2_score_set2 \u001b[32mPASSED\u001b[0m\u001b[32m                      [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m71 deselected\u001b[0m\u001b[32m in 0.57s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sgd.py -k TestR2Score -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-praise",
   "metadata": {},
   "source": [
    "Подготовьте тренировочную и тестовые выборки, обучите на них модель, измерьте качество с помощью новой метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hungarian-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from StandardScaler import StandardScaler\n",
    "from SGDRegressor import SGDRegressor\n",
    "from metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "guided-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 31.934652934745714\n",
      "MAE = 4.018558449522879\n",
      "R^2= 0.5780221674353194\n"
     ]
    }
   ],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "reg = SGDRegressor(max_iter=1).fit(X_train, y_train)\n",
    "prediction = reg.predict(X_test)\n",
    "mse = mean_squared_error(prediction, y_test)\n",
    "mae = mean_absolute_error(prediction, y_test)\n",
    "print(f\"MSE = {mse}\\nMAE = {mae}\\nR^2= {r2_score(y_true=y_test, y_pred=prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-governor",
   "metadata": {},
   "source": [
    "* Какое значение получилось?\n",
    "* Можно ли его как-то интерпретировать?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-extraction",
   "metadata": {},
   "source": [
    "Модель неплохо объясняет данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-sugar",
   "metadata": {},
   "source": [
    "# Продолжение следует\n",
    "\n",
    "Если вы успешно дошли до этой части, то вы проделали большую работу в плане понимания того, как работает алгоритм. Ковырять его мы продолжим в следующей домашней работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-mills",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
